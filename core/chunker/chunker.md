
# 1.length chunker

最基本的 chunker，先用最基本的换行符进行切分，如果切分后很小，则会进行合并成为一个小于 max_size 的 chunk(但不是一定小于的，这是一个软约束，如果全部最小的句子都大于 max_size 的话 chunk 后也大会超出 max_size，如果要硬约束的话要用 recursive chunker)。比如

```
"""
保尔·柯察金：钢铁意志的写照。
保尔·柯察金是苏联作家尼古拉·奥斯特洛夫斯基半自传体小说《钢铁是怎样炼成的》中的主人公，他的一生成为跨越时代的精神偶像，其坚韧不拔的意志和为理想献身的精神激励了无数人。
他的故事，是一部关于个人在时代洪流中，历经磨难、百炼成钢的英雄史诗。
苦难童年与革命启蒙。保尔·柯察金的早年生活充满了艰辛与屈辱。他出生在乌克兰一个贫困的铁路工人家里，年幼丧父，家境的窘迫让他过早地体会到了社会底层的心酸。因不满神父的虚伪和压迫，他在学校里反抗，结果被开除，从此走上了独立谋生的道路。在社会的最底层，他当过食堂杂役，在发电厂做过工，受尽了资本家的剥削和凌辱。
十月革命的炮火彻底改变了保尔的人生轨迹。红军的到来，为他黑暗的生活带来了一缕阳光。老布尔什维克朱赫来的出现，更是为他点亮了革命的灯塔。朱赫来向他讲述了革命的道理，让他懂得了人生的价值和奋斗的意义。在朱赫来的引导下，保尔的思想迅速成长，从一个自发的反抗者，转变为一名自觉的革命战士。
战火中的淬炼与考验。为了保卫新生的苏维埃政权，保尔毅然加入了红军。在残酷的国内战争中，他冲锋陷阵，英勇杀敌，经历了血与火的洗礼。他当过侦察兵，也当过骑兵，在战斗中多次负伤，但始终保持着昂扬的斗志。战争不仅磨练了他的意志，也让他深刻地认识到革命的艰巨与伟大。
在此期间，他也经历了个人情感的波折。他与林务官的女儿冬妮娅曾有过一段纯真的恋情。然而，随着革命的深入，两人在思想上的差距日益显现，最终分道 syllabary。这段经历让他明白，真正的爱情必须建立在共同的理想和信念之上。
和平建设中的奉献与牺牲。战争结束后，保尔并没有停下战斗的脚步。他把满腔的热情投入到恢复国民经济的和平建设中。特别是在修建铁路的艰苦工程中，他和同志们在天寒地冻、物资匮乏的恶劣条件下，凭借着惊人的毅力，顽强地完成了任务。
然而，战争时期留下的多处重伤和长期超负荷的工作，严重摧残了保尔的健康。他不幸患上了伤寒，后来又因旧伤复发而全身瘫痪，最终双目失明。命运的残酷打击，将这位充满活力的年轻人禁锢在了病榻之上。
钢铁意志的最后升华。面对常人无法想象的磨难，保尔·柯察金并未被击垮。当他无法再用身体为革命事业贡献力量时，他选择了用笔作为新的武器。在完全失明、全身瘫痪的情况下，他以惊人的毅力，口述完成了小说《暴风雨所诞生的》。
他用自己的亲身经历，诠释了那段流传后世的名言：“人最宝贵的是生命。生命每个人只有一次。人的一生应当这样度过：当他回首往事的时候，他不会因为虚度年华而悔恨，也不会因为碌碌无为而羞耻；在临死的时候，他能够说：‘我的整个生命和全部精力，都已经献给了世界上最壮丽的事业——为人类的解放而斗争。’”
保尔·柯察金的一生，正是这句名言最生动的写照。他将自己有限的生命，完全奉献给了他所坚信的伟大事业，他的精神，如同经过千锤百炼的钢铁，坚不可摧，熠熠生辉。
"""
```

如果 max_size 非常小，则根据每一个换行符（即每一句话）成为一个 chunk

如果 max_size 非常大，则整段话成为一个 chunk

# 2.markdown chunker

可以自定义 markdown 的标题格式，并且按照markdown语法规则给解析出来，例如

```
# 人工智能发展史

人工智能（Artificial Intelligence，AI）是计算机科学的一个重要分支，旨在创造能够模拟人类智能行为的机器。从概念提出到今天的蓬勃发展，人工智能经历了多个重要的发展阶段。

## 早期探索阶段（1940s-1960s）

### 图灵测试的提出

1950年，英国数学家阿兰·图灵在论文《计算机械与智能》中提出了著名的图灵测试。这个测试成为了判断机器是否具有智能的重要标准。图灵预言，到2000年将会有机器能够通过图灵测试。
```

被解析为

```
{'Header 1': '人工智能发展史'}
('人工智能（Artificial '
 'Intelligence，AI）是计算机科学的一个重要分支，旨在创造能够模拟人类智能行为的机器。从概念提出到今天的蓬勃发展，人工智能经历了多个重要的发展阶段。')
{'Header 1': '人工智能发展史',
 'Header 2': '早期探索阶段（1940s-1960s）',
 'Header 3': '图灵测试的提出'}
'1950年，英国数学家阿兰·图灵在论文《计算机械与智能》中提出了著名的图灵测试。这个测试成为了判断机器是否具有智能的重要标准。图灵预言，到2000年将会有机器能够通过图灵测试。'
```

解析分两个，元数据list[dict[str,str]]和解析文本list[str]

# 3.semantic chunker

先用分词算法把长文本拆成小句子，然后用小模型计算小句子的相似度进行组合，例如

```
TEST_STR = """
光合作用是地球上最重要的化学反应之一，它是植物、藻类和某些细菌利用光能，将二氧化碳和水转化为富能有机物（主要是葡萄糖），并释放出氧气的过程。这个过程不仅为几乎所有生命提供了食物来源，也为我们创造了赖以生存的含氧大气。
深入到细胞层面，光合作用主要在叶绿体中进行。整个过程分为两个主要阶段：光反应和暗反应（也称碳反应）。在光反应阶段，叶绿素等光合色素吸收光能，将水分解成氧气、质子和电子，并将光能转化为化学能储存在ATP和NADPH这两种分子中。这个阶段必须有光才能进行。随后，在暗反应阶段，利用光反应产生的ATP和NADPH，在一种叫做卡尔文循环的系列反应中，将二氧化碳固定并合成为葡萄糖。这个阶段不直接需要光，但依赖于光反应的产物。
从生态学的角度看，光合作用的影响是全球性的和深远的。它构成了地球上绝大多数食物链的基础，所有食草动物的能量最终都来源于植物通过光合作用固定的太阳能。同时，每年通过光合作用消耗的大量二氧化碳，对缓解全球温室效应起到了至关重要的作用。可以说，没有光合作用，地球的生态系统和气候环境将是完全不同的景象。
苹果公司的故事始于1976年，在加州一个不起眼的车库里，史蒂夫·乔布斯和史蒂夫·沃兹尼亚克共同创立了这家公司。他们的第一款产品是Apple I，一款主要面向电子爱好者的电脑主板。随后推出的Apple II取得了巨大的商业成功，它拥有彩色的图形界面和开放的架构，真正开启了个人电脑革命的浪幕，并使苹果迅速成为一家价值数十亿美元的公司。这个初创时期的苹果，充满了理想主义和工程师文化。
进入80年代，苹果面临着来自IBM等巨头的激烈竞争。为了应对挑战，乔布斯主导开发了具有革命性图形用户界面（GUI）和鼠标的Macintosh电脑。1984年，苹果在超级碗期间投放了那则著名的广告，将Macintosh定位为挑战思想禁锢的工具。尽管Macintosh在技术上是开创性的，但其高昂的价格和封闭的生态系统限制了市场份额。随后，由于公司内部的权力斗争，乔布斯于1985年被迫离开了自己亲手创立的公司。
乔布斯离开后，苹果公司进入了一段漫长的迷失期。公司产品线混乱，创新乏力，市场份额持续下滑，一度濒临破产。直到1997年，苹果公司收购了乔布斯创立的NeXT公司，乔布斯才得以戏剧性地回归。他回归后迅速进行了大刀阔斧的改革，砍掉了冗余的产品线，并推出了“Think Different”广告活动，重新点燃了品牌的激情。1998年发布的iMac G3，以其多彩的半透明外壳和一体化设计，震惊了整个行业，标志着苹果复兴的开始。
21世纪初，苹果的创新进入了快车道，彻底改变了多个行业。2001年，iPod的推出颠覆了音乐产业。2007年，iPhone的发布则重新定义了手机，开启了移动互联网时代，并成为公司历史上最成功的产品。紧接着，2010年iPad的问世开创了平板电脑市场。这一系列基于iOS生态系统的产品，构建了强大的护城河，将苹果推向了全球市值最高公司的宝座。
"""
```

被解析为

```
['\n'
 '光合作用是地球上最重要的化学反应之一，它是植物、藻类和某些细菌利用光能，将二氧化碳和水转化为富能有机物（主要是葡萄糖），并释放出氧气的过程。这个过程不仅为几乎所有生命提供了食物来源，也为我们创造了赖以生存的含氧大气。\n'
 '深入到细胞层面，光合作用主要在叶绿体中进行。整个过程分为两个主要阶段：光反应和暗反应（也称碳反应）。在光反应阶段，叶绿素等光合色素吸收光能，将水分解成氧气、质子和电子，并将光能转化为化学能储存在ATP和NADPH这两种分子中。这个阶段必须有光才能进行。随后，在暗反应阶段，利用光反应产生的ATP和NADPH，在一种叫做卡尔文循环的系列反应中，将二氧化碳固定并合成为葡萄糖。这个阶段不直接需要光，但依赖于光反应的产物。\n'
 '从生态学的角度看，光合作用的影响是全球性的和深远的。它构成了地球上绝大多数食物链的基础，所有食草动物的能量最终都来源于植物通过光合作用固定的太阳能。同时，每年通过光合作用消耗的大量二氧化碳，对缓解全球温室效应起到了至关重要的作用。可以说，没有光合作用，地球的生态系统和气候环境将是完全不同的景象。\n'
 '苹果公司的故事始于1976年，在加州一个不起眼的车库里，史蒂夫·乔布斯和史蒂夫·沃兹尼亚克共同创立了这家公司。他们的第一款产品是Apple '
 'I，一款主要面向电子爱好者的电脑主板。随后推出的Apple '
 'II取得了巨大的商业成功，它拥有彩色的图形界面和开放的架构，真正开启了个人电脑革命的浪幕，并使苹果迅速成为一家价值数十亿美元的公司。这个初创时期的苹果，充满了理想主义和工程师文化。\n'
 '进入80年代，苹果面临着来自IBM等巨头的激烈竞争。为了应对挑战，乔布斯主导开发了具有革命性图形用户界面（GUI）和鼠标的Macintosh电脑。1984年，苹果在超级碗期间投放了那则著名的广告，将Macintosh定位为挑战思想禁锢的工具。尽管Macintosh在技术上是开创性的，但其高昂的价格和封闭的生态系统限制了市场份额。随后，由于公司内部的权力斗争，乔布斯于1985年被迫离开了自己亲手创立的公司。\n'
 '乔布斯离开后，苹果公司进入了一段漫长的迷失期。公司产品线混乱，创新乏力，市场份额持续下滑，一度濒临破产。直到1997年，苹果公司收购了乔布斯创立的NeXT公司，乔布斯才得以戏剧性地回归。他回归后迅速进行了大刀阔斧的改革，砍掉了冗余的产品线，并推出了“Think '
 'Different”广告活动，重新点燃了品牌的激情。1998年发布的iMac '
 'G3，以其多彩的半透明外壳和一体化设计，震惊了整个行业，标志着苹果复兴的开始。\n'
 '21世纪初，苹果的创新进入了快车道，彻底改变了多个行业。2001年，iPod的推出颠覆了音乐产业。2007年，iPhone的发布则重新定义了手机，开启了移动互联网时代，并成为公司历史上最成功的产品。紧接着，2010年iPad的问世开创了平板电脑市场。这一系列基于iOS生态系统的产品，构建了强大的护城河，将苹果推向了全球市值最高公司的宝座。\n']
```

# 4.recursive chunker

通过自定义的分隔符一次 chunk，比如["\n\n", "\n", " ", ""]，可以保证文本的数量一定小于某个值，例如

```
TEST_STR = """
深度学习：人工智能的革命性突破。深度学习是机器学习的一个分支，基于人工神经网络，特别是深层神经网络进行学习和模式识别。它模仿人脑的神经元连接方式，通过多层网络结构，能够自动学习数据的层次化特征表示。近年来，深度学习在计算机视觉、自然语言处理、语音识别等领域取得了突破性进展。
神经网络的基础架构。深度学习的核心是神经网络，由输入层、隐藏层和输出层组成。每个神经元通过权重连接到其他神经元，接收输入信号，经过激活函数处理后产生输出。反向传播算法是训练神经网络的关键技术，通过计算损失函数的梯度，逐层更新网络参数，使模型不断优化。
卷积神经网络的图像革命。在计算机视觉领域，卷积神经网络（CNN）是最成功的深度学习架构之一。CNN通过卷积层、池化层和全连接层的组合，能够有效提取图像的空间特征。它在图像分类、物体检测、人脸识别等任务上表现卓越，甚至在某些任务上超越了人类的表现。
循环神经网络处理序列数据。对于时序数据和自然语言，循环神经网络（RNN）及其变体LSTM和GRU表现出色。这些网络能够记住之前的信息，处理变长序列，在机器翻译、语音识别、文本生成等任务中发挥重要作用。Transformer架构的出现进一步推动了自然语言处理的发展。
生成对抗网络的创新应用。生成对抗网络（GAN）由生成器和判别器组成，通过对抗训练产生高质量的合成数据。GAN在图像生成、风格转换、数据增强等方面展现出强大能力，为创意AI和艺术创作开辟了新的可能性。
深度学习的挑战与未来。尽管深度学习取得了巨大成功，但仍面临数据需求量大、可解释性差、计算资源消耗高等挑战。未来的发展方向包括小样本学习、可解释AI、边缘计算优化等，这些将进一步推动人工智能技术的普及和应用。
"""
```

可以被 chunk 为
```
['深度学习：人工智能的革命性突破。深度学',
 '习是机器学习的一个分支，基于人工神经网络',
 '，特别是深层神经网络进行学习和模式识别。',
 '它模仿人脑的神经元连接方式，通过多层网络',
 '结构，能够自动学习数据的层次化特征表示。',
 '近年来，深度学习在计算机视觉、自然语言处',
 '理、语音识别等领域取得了突破性进展。',
 '神经网络的基础架构。深度学习的核心是神',
 '经网络，由输入层、隐藏层和输出层组成。每',
 '个神经元通过权重连接到其他神经元，接收输',
 '入信号，经过激活函数处理后产生输出。反向',
 '传播算法是训练神经网络的关键技术，通过计',
 '算损失函数的梯度，逐层更新网络参数，使模',
 '型不断优化。',
 '卷积神经网络的图像革命。在计算机视觉领',
 '域，卷积神经网络（CNN）是最成功的深度',
 '学习架构之一。CNN通过卷积层、池化层和',
 '全连接层的组合，能够有效提取图像的空间特',
 '征。它在图像分类、物体检测、人脸识别等任',
 '务上表现卓越，甚至在某些任务上超越了人类',
 '的表现。',
 '循环神经网络处理序列数据。对于时序数据',
 '和自然语言，循环神经网络（RNN）及其变',
 '体LSTM和GRU表现出色。这些网络能够',
 '记住之前的信息，处理变长序列，在机器翻译',
 '、语音识别、文本生成等任务中发挥重要作用',
 '。Transformer架构的出现进一步',
 '推动了自然语言处理的发展。',
 '生成对抗网络的创新应用。生成对抗网络（',
 'GAN）由生成器和判别器组成，通过对抗训',
 '练产生高质量的合成数据。GAN在图像生成',
 '、风格转换、数据增强等方面展现出强大能力',
 '，为创意AI和艺术创作开辟了新的可能性。',
 '深度学习的挑战与未来。尽管深度学习取得',
 '了巨大成功，但仍面临数据需求量大、可解释',
 '性差、计算资源消耗高等挑战。未来的发展方',
 '向包括小样本学习、可解释AI、边缘计算优',
 '化等，这些将进一步推动人工智能技术的普及',
 '和应用。']
```

# 5.agentic chunker

让一个agent 与 LLM 交互进行 chunk，效果如下

```
TEST_STR = '''
# 深入探索：大型语言模型与检索增强生成（RAG）

## 什么是检索增强生成（RAG）？
检索增强生成（Retrieval-Augmented Generation，简称RAG）是一种先进的人工智能技术，它将大型语言模型（LLM）的强大生成能力与外部知识库的精确检索能力相结合。简单来说，当模型需要回答一个问题或生成一段文本时，它首先会从一个庞大的数据源（如维基百科、公司内部文档、数据库等）中检索出最相关的几段信息。然后，它将这些检索到的信息作为上下文，连同原始问题一起，提供给语言模型，从而生成一个信息更准确、内容更丰富、更不容易“胡说八道”的回答。这种方式有效地缓解了LLM知识陈旧和产生幻觉的问题。

RAG的核心优势在于它的动态性和可追溯性。由于知识库可以随时更新，RAG系统能够获取最新的信息，这是静态训练的LLM无法比拟的。同时，因为答案是基于检索到的特定文档生成的，我们可以很容易地追溯到信息的来源，增加了系统的透明度和可信度。

## RAG面临的挑战与Agentic Chunker的角色
尽管RAG非常强大，但在实际应用中也面临诸多挑战，其中“分块（Chunking）”策略是至关重要的一环。如果分块做得不好，检索阶段的效果将大打折扣，最终影响生成质量。传统的固定大小分块方法，比如简单地每1000个字符切一刀，很容易将一个完整的语义单元（比如一个关键定义或一个复杂的逻辑论证）硬生生地切开，导致检索到的上下文信息不完整，模型也就无法准确理解。想象一下，一个关键步骤的解释被分在了两个不同的块里，检索系统可能只找到了其中一半，那模型的回答必然是片面的。为了解决这个问题，智能分块技术应运而生。这里的Agentic Chunker就是一个很好的例子，它利用语言模型自身的理解能力来寻找文本中最自然的断点。它不仅仅是看字符数，更是去理解句子结构、段落主题和逻辑关系，力求在不超过设定长度（如1024个字符）的前提下，保持每个分块的语义完整性。这对于处理复杂的长篇文档、法律合同或者技术手册尤为重要，因为这些文档中的信息关联性极强，任何不恰当的分割都可能导致严重的理解偏差。一个优秀的Agentic Chunker能够显著提升RAG系统的“召回率”和“精确率”，是构建高效、可靠的知识问答系统的基石。

## RAG系统的关键步骤
一个典型的RAG系统通常包含以下几个核心步骤：
1.  **数据索引（Indexing）**: 将原始文档（如PDF, TXT, HTML文件）进行预处理，包括清洗、分块（Chunking），然后使用编码模型（Encoder）将每个文本块转换成向量（Vector Embeddings），并存入向量数据库中。
2.  **检索（Retrieval）**: 当用户提出问题时，同样将问题文本转换成向量，然后在向量数据库中进行相似度搜索，找出与问题向量最相近的N个文本块。
3.  **生成（Generation）**: 将检索到的N个文本块作为上下文信息，与用户的原始问题一起，构建成一个完整的提示（Prompt），然后送入大型语言模型进行最终的回答生成。

## 代码示例：一个简单的RAG查询函数
下面是一个伪代码，演示了RAG的基本逻辑。一个好的chunker应该尽量保持这样的代码块完整。

```python
def simple_rag_query(query: str, vector_db: VectorDB, llm: LLM):
    # 1. Retrieve relevant text chunks
    retrieved_chunks = vector_db.search(query, top_k=3)
    
    # 2. Build the prompt with context
    context = "\n".join([chunk.text for chunk in retrieved_chunks])
    prompt = f"""
    Based on the following context, please answer the question.
    Context:
    {context}
    
    Question: {query}
    
    Answer:
    """
    
    # 3. Generate response using the LLM
    response = llm.generate(prompt)
    return response
'''
```

被 chunk 为

```
['\n'
 '# 深入探索：大型语言模型与检索增强生成（RAG）\n'
 '\n'
 '## 什么是检索增强生成（RAG）？\n'
 '检索增强生成（Retrieval-AugmentedGeneration，简称RAG）是一种先进的人工智能技术，它将大型语言模型（LLM）的强大生成能力与外部知识库的精确检索能力相结合。简单来说，当模型需要回答一个问题或生成一段文本时，它首先会从一个庞大的数据源（如维基百科、公司内部文档、数据库等）中检索出最相关的几段信息。然后，它将这些检索到的信息作为上下文，连同原始问题一起，提供给语言模型，从而生成一个信息更准确、内容更丰富、更不容易“胡说八道”的回答。这种方式有效地缓解了LLM知识陈旧和产生幻觉的问题。\n'
 '\n'
 'RAG的核心优势在于它的动态性和可追溯性。由于知识库可以随时更新，RAG系统能够获取最新的信息，这是静态训练的LLM无法比拟的。同时，因为答案是基于检索到的特定文档生成的，我们可以很容易地追溯到信息的来源，增加了系统的透明度和可信度。\n'
 '\n'
 '## RAG面临的挑战与Agentic Chunker的角色\n'
 '尽管RAG非常强大，但在实际应用中也面临诸多挑战，其中“分块（Chunking）”策略是至关重要的一环。如果分块做得不好，检索阶段的效果将大打折扣，最终影响生成质量。传统的固定大小分块方法，比如简单地每1000个字符切一刀，很容易将一个完整的语义单元（比如一个关键定义或一个复杂的逻辑论证）硬生生地切开，导致检索到的上下文信息不完整，模型也就无法准确理解。想象一下，一个关键步骤的解释被分在了两个不同的块里，检索系统可能只找到了其中一半，那模型的回答必然是片面的。为了解决这个问题，智能分块技术应运而生。这里的AgenticChunker就是一个很好的例子，它利用语言模型自身的理解能力来寻找文本中最自然的断点。它不仅仅是看字符数，更是去理解句子结构、段落主题和逻辑关系，力求在不超过设定长度（如1024个字符）的前提下，保持每个分块的语义完整性。这对于处理复杂的长篇文档、法律合同或者技术手册尤为重要，因为这些文档中的信息关联性极强，任何不恰当的分割都可能导致严重的理解偏差。一个优秀的AgenticChunker能够显著提升RAG系统的“召回率”和“精确率”，是构建高效、可靠的知识问答系统的基石。\n',
 '\n'
 '## RAG系统的关键步骤\n'
 '一个典型的RAG系统通常包含以下几个核心步骤：\n'
 '1.  **数据索引（Indexing）**: 将原始文档（如PDF, TXT, '
 'HTML文件）进行预处理，包括清洗、分块（Chunking），然后使用编码模型（Encoder）将每个文本块转换成向量（Vector '
 'Embeddings），并存入向量数据库中。\n'
 '2.  **检索（Retrieval）**: '
 '当用户提出问题时，同样将问题文本转换成向量，然后在向量数据库中进行相似度搜索，找出与问题向量最相近的N个文本块。\n'
 '3.  **生成（Generation）**: '
 '将检索到的N个文本块作为上下文信息，与用户的原始问题一起，构建成一个完整的提示（Prompt），然后送入大型语言模型进行最终的回答生成。\n',
 '\n## 代码示例：一个简单的RAG查询函数\n下面是一个伪代码，演示了RAG的基本逻辑。一个好的chunker应该尽量保持这样的代码块完整。\n',
 '\n'
 '```python\n'
 'def simple_rag_query(query: str, vector_db: VectorDB, llm: LLM):\n',
 '    # 1. Retrieve relevant text chunks\n',
 '    retrieved_chunks = vector_db.search(query, top_k=3)\n',
 '    \n'
 '    # 2. Build the prompt with context\n'
 '    context = "\n'
 '".join([chunk.text for chunk in retrieved_chunks])\n'
 '    prompt = f"""\n'
 '    Based on the following context, please answer the question.\n'
 '    Context:\n'
 '    {context}\n'
 '    \n'
 '    Question: {query}\n'
 '    \n'
 '    Answer:\n'
 '    """\n',
 '    \n    # 3. Generate response using the LLM\n',
 '    response = llm.generate(prompt)\n',
 '    return response\n']
```

# more chunker

